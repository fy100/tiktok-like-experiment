{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "Table of Contents:\n",
    "* [Importing Data](#one)\n",
    "* [Data Manipulation](#two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cw/4tmbrj3d1pzd4rhyrm8vnwyc0000gn/T/ipykernel_69598/4080736814.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Data <a class=\"anchor\" id=\"one\"></a>\n",
    "For each scenario, create data frame to organize which csv files belong to which scenario and test user <br>\n",
    "In order for the following code blocks to run, change variable `prefix` below to the file path stored in your computer for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"/Users/carolinejung/tiktok-like-experiment/\" # CHANGE ME!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc2_files = pd.DataFrame(\n",
    "    [{\"run\": 1, \"user\": \"control\", \"videos\": \"all\", \"path\": prefix+\"data/-1_Sec02Gr2Sc2Cntrl_CJ_02-12-19-31_like_by_hashtag_data_all_videos.csv\"},\n",
    "     {\"run\": 1, \"user\": \"control\", \"videos\": \"liked\", \"path\": prefix+\"data/-1_Sec02Gr2Sc2Cntrl_CJ_02-12-19-31_like_by_hashtag_data_liked_videos.csv\"},\n",
    "     {\"run\": 1, \"user\": \"active\", \"videos\": \"all\", \"path\": prefix+\"data/2_Sec02Gr2Sc2Activ_CJ_02-12-19-30_like_by_control_data_all_videos.csv\"},\n",
    "     {\"run\": 1, \"user\": \"active\", \"videos\": \"liked\", \"path\": prefix+\"data/2_Sec02Gr2Sc2Activ_CJ_02-12-19-30_like_by_control_data_liked_videos.csv\"},\n",
    "\n",
    "     {\"run\": 2, \"user\": \"control\", \"videos\": \"all\", \"path\": prefix+\"data/-1_Sec02Gr2Sc2Cntrl_CJ_02-12-19-40_like_by_hashtag_data_all_videos.csv\"},\n",
    "     {\"run\": 2, \"user\": \"control\", \"videos\": \"liked\", \"path\": prefix+\"data/-1_Sec02Gr2Sc2Cntrl_CJ_02-12-19-40_like_by_hashtag_data_liked_videos.csv\"},\n",
    "     {\"run\": 2, \"user\": \"active\", \"videos\": \"all\", \"path\": prefix+\"data/2_Sec02Gr2Sc2Activ_CJ_02-12-19-39_like_by_control_data_all_videos.csv\"},\n",
    "     {\"run\": 2, \"user\": \"active\", \"videos\": \"liked\", \"path\": prefix+\"data/2_Sec02Gr2Sc2Activ_CJ_02-12-19-39_like_by_control_data_liked_videos.csv\"},\n",
    "\n",
    "     {\"run\": 3, \"user\": \"control\", \"videos\": \"all\", \"path\": prefix+\"data/-1_Sec02Gr2Sc2Cntrl_CJ_02-13-13-31_like_by_hashtag_data_all_videos.csv\"},\n",
    "     {\"run\": 3, \"user\": \"control\", \"videos\": \"liked\", \"path\": prefix+\"data/-1_Sec02Gr2Sc2Cntrl_CJ_02-13-13-31_like_by_hashtag_data_liked_videos.csv\"},\n",
    "     {\"run\": 3, \"user\": \"active\", \"videos\": \"all\", \"path\": prefix+\"data/2_Sec02Gr2Sc2Activ_CJ_02-13-13-30_like_by_control_data_all_videos.csv\"},\n",
    "     {\"run\": 3, \"user\": \"active\", \"videos\": \"liked\", \"path\": prefix+\"data/2_Sec02Gr2Sc2Activ_CJ_02-13-13-30_like_by_control_data_liked_videos.csv\"},\n",
    "\n",
    "     {\"run\": 4, \"user\": \"control\", \"videos\": \"all\", \"path\": prefix+\"data/-1_Sec02Gr2Sc2Cntrl_CJ_02-13-13-37_like_by_hashtag_data_all_videos.csv\"},\n",
    "     {\"run\": 4, \"user\": \"control\", \"videos\": \"liked\", \"path\": prefix+\"data/-1_Sec02Gr2Sc2Cntrl_CJ_02-13-13-37_like_by_hashtag_data_liked_videos.csv\"},\n",
    "     {\"run\": 4, \"user\": \"active\", \"videos\": \"all\", \"path\": prefix+\"data/2_Sec02Gr2Sc2Activ_CJ_02-13-13-36_like_by_control_data_all_videos.csv\"},\n",
    "     {\"run\": 4, \"user\": \"active\", \"videos\": \"liked\", \"path\": prefix+\"data/2_Sec02Gr2Sc2Activ_CJ_02-13-13-36_like_by_control_data_liked_videos.csv\"},\n",
    "\n",
    "     {\"run\": 5, \"user\": \"control\", \"videos\": \"all\", \"path\": prefix+\"data/-1_Sec02Gr2Sc2Cntrl_CJ_02-13-13-53_like_by_hashtag_data_all_videos.csv\"},\n",
    "     {\"run\": 5, \"user\": \"control\", \"videos\": \"liked\", \"path\": prefix+\"data/-1_Sec02Gr2Sc2Cntrl_CJ_02-13-13-53_like_by_hashtag_data_liked_videos.csv\"},\n",
    "     {\"run\": 5, \"user\": \"active\", \"videos\": \"all\", \"path\": prefix+\"data/2_Sec02Gr2Sc2Activ_CJ_02-13-13-52_like_by_control_data_all_videos.csv\"},\n",
    "     {\"run\": 5, \"user\": \"active\", \"videos\": \"liked\", \"path\": prefix+\"data/2_Sec02Gr2Sc2Activ_CJ_02-13-13-52_like_by_control_data_liked_videos.csv\"}\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Manipulation <a class=\"anchor\" id=\"two\"></a>\n",
    "For each scenario:\n",
    "1. Read the csvs and name each dataframe based on its run number, user type, and types of videos stored\n",
    "2. Combine all runs into one single dataframe for each scenario for each user type and type of video stored (control_all, active_all, active_liked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_and_name_dfs(sc_files):\n",
    "    sc = {}\n",
    "    for row in range(sc_files.shape[0]):\n",
    "        var_name = \"r{}_{}_{}\".format(sc_files.iloc[row][\"run\"], sc_files.iloc[row][\"user\"], sc_files.iloc[row][\"videos\"])\n",
    "        sc[var_name] = pd.read_csv(sc_files.iloc[row][\"path\"])\n",
    "        sc[var_name][\"run\"] = sc_files.iloc[row][\"run\"] #add new column for run number\n",
    "    return sc\n",
    "\n",
    "sc2 = read_csv_and_name_dfs(sc2_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_runs(sc):\n",
    "    to_merge_control_all = []\n",
    "    to_merge_active_all = []\n",
    "    to_merge_active_liked = []\n",
    "    for run_num in range(1, 6): #CHANGE LATER TO 1 TO 21\n",
    "        to_merge_control_all.append(sc[\"r{}_control_all\".format(run_num)])\n",
    "        to_merge_active_all.append(sc[\"r{}_active_all\".format(run_num)])\n",
    "        to_merge_active_liked.append(sc[\"r{}_active_liked\".format(run_num)])\n",
    "\n",
    "    control_all = pd.concat(to_merge_control_all)\n",
    "    active_all = pd.concat(to_merge_active_all)\n",
    "    active_liked = pd.concat(to_merge_active_liked)\n",
    "    return (control_all, active_all, active_liked)\n",
    "\n",
    "sc2_control_all = merge_runs(sc2)[0]\n",
    "sc2_active_all = merge_runs(sc2)[1]\n",
    "sc2_active_liked = merge_runs(sc2)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: From now on, to access the information from a certain csv file, call the following: sc**2**[\"r**1\\_control\\_all**\"]\n",
    "where the bolded text should be replaced with\n",
    "* scenario number (1,2,3,4,5,6)\n",
    "* run number (1,2,3,... 20)\n",
    "* if user is control or active (control, active)\n",
    "* if the data has all or only liked videos (all, liked) <br>\n",
    "For example: `sc2[\"r1_control_all\"]` gives (as a dataframe) all videos that scenario 2's control user saw **for only the first run**\n",
    "\n",
    "\n",
    "NOTE: To access information for all runs for a certain scenario's user and videos seen, call the following: sc**2\\_control\\_all**\n",
    "where the bolded text should be replaced with\n",
    "* scenario number (1,2,3,4,5,6)\n",
    "* either one of control_all, active_all, or active_liked <br>\n",
    "For example: `sc2_active_all` gives (as a dataframe) all videos that scenario 2's active user saw **during all 20 runs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you can always access a subset of the data for a specific run, by the following syntax: scenario_user_video[scenario_user_video.run == specificrunnumber].\n",
    "\n",
    "For example, `sc2_active_all[sc2_active_all.run == 2]` is equivalent to `sc2[\"r2_active_all\"]` <br>\n",
    "(which gives all the videos that scenario 2's active user saw for only the 2nd run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyzing Hashtags <a class=\"anchor\" id=\"two\"></a>\n",
    "\n",
    "### 3.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_to_ignore = [\"fyp\", \"viral\", \"foryou\", \"foryoupage\", \"tiktok\", \"fy\", \"fypage\", \"fypchallenge\"]\n",
    "def clean_hashtags(df):\n",
    "    noNA_hash = []\n",
    "    NAcount = 0\n",
    "    for row in range(df.shape[0]): #for each post\n",
    "        if type(df.hashtag.iloc[row])==type(\"\"): #if not NaN types\n",
    "            list_of_hash = df.hashtag.iloc[row].split(\",\")\n",
    "            noNA_hash.append([hash.strip() for hash in list_of_hash])\n",
    "        else:\n",
    "            NAcount += 1\n",
    "    full_list = list(set([a for b in noNA_hash for a in b]))\n",
    "    return (list(filter(lambda x: x not in hash_to_ignore, full_list)), NAcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Frequency Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "freq = pd.Series(clean_hashtags(sc2[\"r1_control_all\"])[0]).value_counts()\n",
    "print(freq[freq>1]) #no explicit repetition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Jaccard Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity: 0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union\n",
    "\n",
    "# an example for how to run this:\n",
    "set_a = set([\"cookies\", \"baking\", \"food\", \"recipe\"])\n",
    "set_b = set([\"oven\", \"baking\", \"cook\", \"bread\"])\n",
    "similarity = jaccard_similarity(set_a, set_b)\n",
    "print(\"Jaccard Similarity:\", similarity)\n",
    "\n",
    "\n",
    "# a) comparison 1: control vs active feeds (analyzing possible feed divergence)\n",
    "#scen1_control_all = set(sc1[\"r1_control_all\"])\n",
    "#scen1_active_all = set()\n",
    "\n",
    "# b) comparison 2: predefined hashtags to like vs actually liked posts (to compare similarities between other hashtags that were not predefined but still appeared for similar posts)\n",
    "#scen1_predefined_hash = set()\n",
    "#scen1_active_like = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "music\n",
      "original sound - Gavin.kernstinee                              2\n",
      "AIN'T GONNA ANSWER - NLE Choppa & Lil Wayne                    2\n",
      "I Wouldnt Mind - ♱                                             1\n",
      "original sound - Alex                                          1\n",
      "som original - rinx                                            1\n",
      "                                                              ..\n",
      "original sound - fr0sty_rick                                   1\n",
      "Monkeys Spinning Monkeys - Kevin MacLeod & Kevin The Monkey    1\n",
      "Oi - My Soul Gone                                              1\n",
      "original sound - Sam Middleton                                 1\n",
      "original sound - squishiesophie                                1\n",
      "Name: count, Length: 80, dtype: int64\n",
      "author\n",
      "mirandahshaul         2\n",
      "didiios               1\n",
      "dangmattsmith         1\n",
      "vaynessvalery         1\n",
      "wolf.spectrum         1\n",
      "                     ..\n",
      "leci.bby              1\n",
      "madelineandstephen    1\n",
      "radicalraphael        1\n",
      "itz_justlola          1\n",
      "squishiesophie        1\n",
      "Name: count, Length: 81, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## ANALYZING MUSIC ----------------------------------------------------------------------------------\n",
    "mus = sc2[\"r1_control_all\"].music.value_counts()\n",
    "print(mus)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ANALYZING AUTHOR ---------------------------------------------------------------------------------\n",
    "aut = sc2[\"r1_control_all\"].author.value_counts()\n",
    "print(aut)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
